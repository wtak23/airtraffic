{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Aim-of-notebook\" data-toc-modified-id=\"Aim-of-notebook-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Aim of notebook</a></div><div class=\"lev1 toc-item\"><a href=\"#Load-the-main-airport-traffic-data\" data-toc-modified-id=\"Load-the-main-airport-traffic-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load the main airport traffic data</a></div><div class=\"lev1 toc-item\"><a href=\"#Load-lookup-table-provided-by-BTS\" data-toc-modified-id=\"Load-lookup-table-provided-by-BTS-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Load lookup table provided by BTS</a></div><div class=\"lev1 toc-item\"><a href=\"#Create-enhanced-lookuptable\" data-toc-modified-id=\"Create-enhanced-lookuptable-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Create <em>enhanced</em> lookuptable</a></div><div class=\"lev2 toc-item\"><a href=\"#Remove-Code-that-is-not-present-our-dataset\" data-toc-modified-id=\"Remove-Code-that-is-not-present-our-dataset-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Remove Code that is not present our dataset</a></div><div class=\"lev2 toc-item\"><a href=\"#Parse-state,city,-and-airport-name-from-'Description'-field\" data-toc-modified-id=\"Parse-state,city,-and-airport-name-from-'Description'-field-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Parse state,city, and airport-name from 'Description' field</a></div><div class=\"lev2 toc-item\"><a href=\"#Add-state-'region'-information\" data-toc-modified-id=\"Add-state-'region'-information-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Add state 'region' information</a></div><div class=\"lev2 toc-item\"><a href=\"#Add-airport-latitude-and-longitude-information-using-Google-geocoder\" data-toc-modified-id=\"Add-airport-latitude-and-longitude-information-using-Google-geocoder-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Add airport latitude and longitude information using Google geocoder</a></div><div class=\"lev2 toc-item\"><a href=\"#Add-column-with-both-city-and-state\" data-toc-modified-id=\"Add-column-with-both-city-and-state-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Add column with both city and state</a></div><div class=\"lev1 toc-item\"><a href=\"#All-done.-Save-dataframe-on-disk\" data-toc-modified-id=\"All-done.-Save-dataframe-on-disk-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>All done. Save dataframe on disk</a></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from pprint import pprint\n",
    "from util import print_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aim of notebook\n",
    "\n",
    "- The [airport traffic dataset](http://www.transtats.bts.gov/DL_SelectFields.asp?Table_ID=236&DB_Short_Name=On-Time) encodes the airport with unique ID numbers.\n",
    "\n",
    "- In this notebook, we'll create an *enhanced lookup-table* by taking the lookup table provided by the BTS ([download link](http://www.transtats.bts.gov/Download_Lookup.asp?Lookup=L_AIRPORT_ID)) and adding additional relevant information regarding the airport (such as latitude/longitutde info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the main airport traffic data\n",
    "\n",
    "- Load 3 years worth of air-traffic data provided by BTS ([link](http://www.transtats.bts.gov/DL_SelectFields.asp?Table_ID=236&DB_Short_Name=On-Time))\n",
    "- (from November 2013 to October 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ... load dataframe from 2013-11.zip \n",
      " ... load dataframe from 2013-12.zip \n",
      " ... load dataframe from 2014-01.zip \n",
      " ... load dataframe from 2014-02.zip \n",
      " ... load dataframe from 2014-03.zip \n",
      " ... load dataframe from 2014-04.zip \n",
      " ... load dataframe from 2014-05.zip \n",
      " ... load dataframe from 2014-06.zip \n",
      " ... load dataframe from 2014-07.zip \n",
      " ... load dataframe from 2014-08.zip \n",
      " ... load dataframe from 2014-09.zip \n",
      " ... load dataframe from 2014-10.zip \n",
      " ... load dataframe from 2014-11.zip \n",
      " ... load dataframe from 2014-12.zip \n",
      " ... load dataframe from 2015-01.zip \n",
      " ... load dataframe from 2015-02.zip \n",
      " ... load dataframe from 2015-03.zip \n",
      " ... load dataframe from 2015-04.zip \n",
      " ... load dataframe from 2015-05.zip \n",
      " ... load dataframe from 2015-06.zip \n",
      " ... load dataframe from 2015-07.zip \n",
      " ... load dataframe from 2015-08.zip \n",
      " ... load dataframe from 2015-09.zip \n",
      " ... load dataframe from 2015-10.zip \n",
      " ... load dataframe from 2015-11.zip \n",
      " ... load dataframe from 2015-12.zip \n",
      " ... load dataframe from 2016-01.zip \n",
      " ... load dataframe from 2016-02.zip \n",
      " ... load dataframe from 2016-03.zip \n",
      " ... load dataframe from 2016-04.zip \n",
      " ... load dataframe from 2016-05.zip \n",
      " ... load dataframe from 2016-06.zip \n",
      " ... load dataframe from 2016-07.zip \n",
      " ... load dataframe from 2016-08.zip \n",
      " ... load dataframe from 2016-09.zip \n",
      " ... load dataframe from 2016-10.zip \n"
     ]
    }
   ],
   "source": [
    "from util import load_airport_data_3years\n",
    "df_data = load_airport_data_3years()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17364696, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>QUARTER</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>ORIGIN_AIRPORT_ID</th>\n",
       "      <th>DEST_AIRPORT_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>12478</td>\n",
       "      <td>10693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12478</td>\n",
       "      <td>10693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>12478</td>\n",
       "      <td>10693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>12478</td>\n",
       "      <td>10693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>12478</td>\n",
       "      <td>10693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR  QUARTER  MONTH  DAY_OF_MONTH  DAY_OF_WEEK  ORIGIN_AIRPORT_ID  \\\n",
       "0  2013        4     11             3            7              12478   \n",
       "1  2013        4     11             4            1              12478   \n",
       "2  2013        4     11             5            2              12478   \n",
       "3  2013        4     11             6            3              12478   \n",
       "4  2013        4     11             7            4              12478   \n",
       "\n",
       "   DEST_AIRPORT_ID  \n",
       "0            10693  \n",
       "1            10693  \n",
       "2            10693  \n",
       "3            10693  \n",
       "4            10693  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print df_data.shape\n",
    "df_data.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load lookup table provided by BTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6409, 2)\n"
     ]
    }
   ],
   "source": [
    "df_lookup = pd.read_csv('../data/L_AIRPORT_ID.csv')\n",
    "print df_lookup.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create *enhanced* lookuptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>Afognak Lake, AK: Afognak Lake Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10003</td>\n",
       "      <td>Granite Mountain, AK: Bear Creek Mining Strip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10004</td>\n",
       "      <td>Lik, AK: Lik Mining Camp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10005</td>\n",
       "      <td>Little Squaw, AK: Little Squaw Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10006</td>\n",
       "      <td>Kizhuyak, AK: Kizhuyak Bay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10007</td>\n",
       "      <td>Klawock, AK: Klawock Seaplane Base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10008</td>\n",
       "      <td>Elizabeth Island, AK: Elizabeth Island Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10009</td>\n",
       "      <td>Homer, AK: Augustin Island</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10010</td>\n",
       "      <td>Hudson, NY: Columbia County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10011</td>\n",
       "      <td>Peach Springs, AZ: Grand Canyon West</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Code                                     Description\n",
       "0  10001          Afognak Lake, AK: Afognak Lake Airport\n",
       "1  10003   Granite Mountain, AK: Bear Creek Mining Strip\n",
       "2  10004                        Lik, AK: Lik Mining Camp\n",
       "3  10005          Little Squaw, AK: Little Squaw Airport\n",
       "4  10006                      Kizhuyak, AK: Kizhuyak Bay\n",
       "5  10007              Klawock, AK: Klawock Seaplane Base\n",
       "6  10008  Elizabeth Island, AK: Elizabeth Island Airport\n",
       "7  10009                      Homer, AK: Augustin Island\n",
       "8  10010                     Hudson, NY: Columbia County\n",
       "9  10011            Peach Springs, AZ: Grand Canyon West"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lookup.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Code that is not present our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6409 Airport-Codes in the lookup table\n",
      "There are 334 unique airport-codes in our dataset\n"
     ]
    }
   ],
   "source": [
    "# unique ID's in the dataset\n",
    "uniq_orig = df_data['ORIGIN_AIRPORT_ID'].unique().tolist() \n",
    "uniq_dest = df_data['DEST_AIRPORT_ID'].unique().tolist()\n",
    "\n",
    "# apply ``set`` function to get unique items in concatenated list\n",
    "uniq_id = list(set(uniq_orig + uniq_dest))\n",
    "\n",
    "print \"There are {} Airport-Codes in the lookup table\".format(df_lookup.shape[0])\n",
    "print \"There are {} unique airport-codes in our dataset\".format(uniq_id.__len__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's filter/drop the rows/records that we do not need in our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(334, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10135</td>\n",
       "      <td>Allentown/Bethlehem/Easton, PA: Lehigh Valley ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10136</td>\n",
       "      <td>Abilene, TX: Abilene Regional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10140</td>\n",
       "      <td>Albuquerque, NM: Albuquerque International Sun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10141</td>\n",
       "      <td>Aberdeen, SD: Aberdeen Regional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10146</td>\n",
       "      <td>Albany, GA: Southwest Georgia Regional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10154</td>\n",
       "      <td>Nantucket, MA: Nantucket Memorial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10155</td>\n",
       "      <td>Waco, TX: Waco Regional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10157</td>\n",
       "      <td>Arcata/Eureka, CA: Arcata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10158</td>\n",
       "      <td>Atlantic City, NJ: Atlantic City International</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10165</td>\n",
       "      <td>Adak Island, AK: Adak</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Code                                        Description\n",
       "0  10135  Allentown/Bethlehem/Easton, PA: Lehigh Valley ...\n",
       "1  10136                      Abilene, TX: Abilene Regional\n",
       "2  10140  Albuquerque, NM: Albuquerque International Sun...\n",
       "3  10141                    Aberdeen, SD: Aberdeen Regional\n",
       "4  10146             Albany, GA: Southwest Georgia Regional\n",
       "5  10154                  Nantucket, MA: Nantucket Memorial\n",
       "6  10155                            Waco, TX: Waco Regional\n",
       "7  10157                          Arcata/Eureka, CA: Arcata\n",
       "8  10158     Atlantic City, NJ: Atlantic City International\n",
       "9  10165                              Adak Island, AK: Adak"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only keep the items in the main dataframe\n",
    "_mask = df_lookup['Code'].isin( uniq_id )\n",
    "df_lookup = df_lookup[ _mask ].reset_index(drop=True)\n",
    "\n",
    "print df_lookup.shape\n",
    "df_lookup.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse state,city, and airport-name from 'Description' field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Above we realize that the ``Description`` field contains information regarding the *city*, *state*, and *name* of the airport.\n",
    "\n",
    "- Let's create individual field for each information.\n",
    "\n",
    "- Fortunately, the ``Description`` column uses a comma (``,``) and colon (``:``) to delimit the City, State, Airport-name information, so splitting these are is straightforward.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Airport': 'Lehigh Valley International',\n",
      "  'City': 'Allentown/Bethlehem/Easton',\n",
      "  'State': 'PA'},\n",
      " {'Airport': 'Abilene Regional', 'City': 'Abilene', 'State': 'TX'},\n",
      " {'Airport': 'Albuquerque International Sunport',\n",
      "  'City': 'Albuquerque',\n",
      "  'State': 'NM'},\n",
      " {'Airport': 'Aberdeen Regional', 'City': 'Aberdeen', 'State': 'SD'},\n",
      " {'Airport': 'Southwest Georgia Regional', 'City': 'Albany', 'State': 'GA'}]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airport</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lehigh Valley International</td>\n",
       "      <td>Allentown/Bethlehem/Easton</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abilene Regional</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albuquerque International Sunport</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aberdeen Regional</td>\n",
       "      <td>Aberdeen</td>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Southwest Georgia Regional</td>\n",
       "      <td>Albany</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Airport                        City State\n",
       "0        Lehigh Valley International  Allentown/Bethlehem/Easton    PA\n",
       "1                   Abilene Regional                     Abilene    TX\n",
       "2  Albuquerque International Sunport                 Albuquerque    NM\n",
       "3                  Aberdeen Regional                    Aberdeen    SD\n",
       "4         Southwest Georgia Regional                      Albany    GA"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply string \"split\" method to break information up\n",
    "df_parse = map(lambda splits: {'City':splits[0],'State':splits[2],'Airport':splits[4]},\n",
    "               df_lookup['Description'].str.split(r'(,\\s|:\\s)') )\n",
    "\n",
    "pprint(df_parse[:5])\n",
    "\n",
    "# convert dict to dataframe\n",
    "df_parse = pd.DataFrame(df_parse)\n",
    "df_parse.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(334, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Description</th>\n",
       "      <th>Airport</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10135</td>\n",
       "      <td>Allentown/Bethlehem/Easton, PA: Lehigh Valley ...</td>\n",
       "      <td>Lehigh Valley International</td>\n",
       "      <td>Allentown/Bethlehem/Easton</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10136</td>\n",
       "      <td>Abilene, TX: Abilene Regional</td>\n",
       "      <td>Abilene Regional</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10140</td>\n",
       "      <td>Albuquerque, NM: Albuquerque International Sun...</td>\n",
       "      <td>Albuquerque International Sunport</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10141</td>\n",
       "      <td>Aberdeen, SD: Aberdeen Regional</td>\n",
       "      <td>Aberdeen Regional</td>\n",
       "      <td>Aberdeen</td>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10146</td>\n",
       "      <td>Albany, GA: Southwest Georgia Regional</td>\n",
       "      <td>Southwest Georgia Regional</td>\n",
       "      <td>Albany</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Code                                        Description  \\\n",
       "0  10135  Allentown/Bethlehem/Easton, PA: Lehigh Valley ...   \n",
       "1  10136                      Abilene, TX: Abilene Regional   \n",
       "2  10140  Albuquerque, NM: Albuquerque International Sun...   \n",
       "3  10141                    Aberdeen, SD: Aberdeen Regional   \n",
       "4  10146             Albany, GA: Southwest Georgia Regional   \n",
       "\n",
       "                             Airport                        City State  \n",
       "0        Lehigh Valley International  Allentown/Bethlehem/Easton    PA  \n",
       "1                   Abilene Regional                     Abilene    TX  \n",
       "2  Albuquerque International Sunport                 Albuquerque    NM  \n",
       "3                  Aberdeen Regional                    Aberdeen    SD  \n",
       "4         Southwest Georgia Regional                      Albany    GA  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we can readily add these information to our lookup table\n",
    "df_lookup = df_lookup.join(df_parse)\n",
    "\n",
    "print df_lookup.shape\n",
    "df_lookup.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add state 'region' information\n",
    "\n",
    "I also would like to study patterns among the four-regions in the United States: \n",
    "\n",
    "(1) Northeast\n",
    "(2) South\n",
    "(3) West\n",
    "(4) Midwest\n",
    "\n",
    "I saved a json lookup file for this purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"Northeast\" : [\"Connecticut\",\"Maine\", \"Massachusetts\", \"New Hampshire\", \"Rhode Island\", \"Vermont\",\"New Jersey\", \"New York\", \"Pennsylvania\"],\n",
      "\"Midwest\"   : [\"Illinois\", \"Indiana\", \"Michigan\", \"Ohio\", \"Wisconsin\", \"Iowa\", \"Kansas\", \"Minnesota\", \"Missouri\", \"Nebraska\", \"North Dakota\", \"South Dakota\"],\n",
      "\"South\"     : [ \"Delaware\", \"Florida\", \"Georgia\", \"Maryland\", \"North Carolina\", \"South Carolina\", \"Virginia\", \"District of Columbia\", \"West Virginia\",             \"Alabama\", \"Kentucky\", \"Mississippi\", \"Tennessee\",\"Arkansas\", \"Louisiana\", \"Oklahoma\", \"Texas\"],\n",
      "\"West\"      : [\"Arizona\", \"Colorado\", \"Idaho\", \"Montana\", \"Nevada\", \"New Mexico\", \"Utah\",  \"Wyoming\", \"Alaska\", \"California\", \"Hawaii\", \"Oregon\", \"Washington\"]\n",
      "}"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat ../data/us_states_regions.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'West', u'Northeast', u'Midwest', u'South']\n",
      "[[u'Arizona', u'Colorado', u'Idaho', u'Montana', u'Nevada', u'New Mexico', u'Utah', u'Wyoming', u'Alaska', u'California', u'Hawaii', u'Oregon', u'Washington'], [u'Connecticut', u'Maine', u'Massachusetts', u'New Hampshire', u'Rhode Island', u'Vermont', u'New Jersey', u'New York', u'Pennsylvania'], [u'Illinois', u'Indiana', u'Michigan', u'Ohio', u'Wisconsin', u'Iowa', u'Kansas', u'Minnesota', u'Missouri', u'Nebraska', u'North Dakota', u'South Dakota'], [u'Delaware', u'Florida', u'Georgia', u'Maryland', u'North Carolina', u'South Carolina', u'Virginia', u'District of Columbia', u'West Virginia', u'Alabama', u'Kentucky', u'Mississippi', u'Tennessee', u'Arkansas', u'Louisiana', u'Oklahoma', u'Texas']]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('../data/us_states_regions.json','r') as f:\n",
    "    regions = json.load(f)\n",
    "\n",
    "print regions.keys()\n",
    "print regions.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Idaho</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Montana</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      State Region\n",
       "0   Arizona   West\n",
       "1  Colorado   West\n",
       "2     Idaho   West\n",
       "3   Montana   West\n",
       "4    Nevada   West"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_region = []\n",
    "for key in regions:\n",
    "    _dftmp = pd.DataFrame( regions[key], columns=['State']  )\n",
    "    _dftmp['Region'] = key\n",
    "    df_region.append(_dftmp)\n",
    "    \n",
    "df_region = pd.concat(df_region,ignore_index=True)\n",
    "\n",
    "df_region.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a hash-table (source) to map state name to its abbreviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AZ</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CO</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MT</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NV</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State Region\n",
       "0    AZ   West\n",
       "1    CO   West\n",
       "2    ID   West\n",
       "3    MT   West\n",
       "4    NV   West"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from util import hash_state_to_abbrev\n",
    "hash_state = hash_state_to_abbrev()\n",
    "\n",
    "df_region['State'] = df_region['State'].map(lambda key: hash_state[key])\n",
    "df_region.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Description</th>\n",
       "      <th>Airport</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10135</td>\n",
       "      <td>Allentown/Bethlehem/Easton, PA: Lehigh Valley ...</td>\n",
       "      <td>Lehigh Valley International</td>\n",
       "      <td>Allentown/Bethlehem/Easton</td>\n",
       "      <td>PA</td>\n",
       "      <td>Northeast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10136</td>\n",
       "      <td>Abilene, TX: Abilene Regional</td>\n",
       "      <td>Abilene Regional</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10140</td>\n",
       "      <td>Albuquerque, NM: Albuquerque International Sun...</td>\n",
       "      <td>Albuquerque International Sunport</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>NM</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10141</td>\n",
       "      <td>Aberdeen, SD: Aberdeen Regional</td>\n",
       "      <td>Aberdeen Regional</td>\n",
       "      <td>Aberdeen</td>\n",
       "      <td>SD</td>\n",
       "      <td>Midwest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10146</td>\n",
       "      <td>Albany, GA: Southwest Georgia Regional</td>\n",
       "      <td>Southwest Georgia Regional</td>\n",
       "      <td>Albany</td>\n",
       "      <td>GA</td>\n",
       "      <td>South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10154</td>\n",
       "      <td>Nantucket, MA: Nantucket Memorial</td>\n",
       "      <td>Nantucket Memorial</td>\n",
       "      <td>Nantucket</td>\n",
       "      <td>MA</td>\n",
       "      <td>Northeast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10155</td>\n",
       "      <td>Waco, TX: Waco Regional</td>\n",
       "      <td>Waco Regional</td>\n",
       "      <td>Waco</td>\n",
       "      <td>TX</td>\n",
       "      <td>South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10157</td>\n",
       "      <td>Arcata/Eureka, CA: Arcata</td>\n",
       "      <td>Arcata</td>\n",
       "      <td>Arcata/Eureka</td>\n",
       "      <td>CA</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10158</td>\n",
       "      <td>Atlantic City, NJ: Atlantic City International</td>\n",
       "      <td>Atlantic City International</td>\n",
       "      <td>Atlantic City</td>\n",
       "      <td>NJ</td>\n",
       "      <td>Northeast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10165</td>\n",
       "      <td>Adak Island, AK: Adak</td>\n",
       "      <td>Adak</td>\n",
       "      <td>Adak Island</td>\n",
       "      <td>AK</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Code                                        Description  \\\n",
       "0  10135  Allentown/Bethlehem/Easton, PA: Lehigh Valley ...   \n",
       "1  10136                      Abilene, TX: Abilene Regional   \n",
       "2  10140  Albuquerque, NM: Albuquerque International Sun...   \n",
       "3  10141                    Aberdeen, SD: Aberdeen Regional   \n",
       "4  10146             Albany, GA: Southwest Georgia Regional   \n",
       "5  10154                  Nantucket, MA: Nantucket Memorial   \n",
       "6  10155                            Waco, TX: Waco Regional   \n",
       "7  10157                          Arcata/Eureka, CA: Arcata   \n",
       "8  10158     Atlantic City, NJ: Atlantic City International   \n",
       "9  10165                              Adak Island, AK: Adak   \n",
       "\n",
       "                             Airport                        City State  \\\n",
       "0        Lehigh Valley International  Allentown/Bethlehem/Easton    PA   \n",
       "1                   Abilene Regional                     Abilene    TX   \n",
       "2  Albuquerque International Sunport                 Albuquerque    NM   \n",
       "3                  Aberdeen Regional                    Aberdeen    SD   \n",
       "4         Southwest Georgia Regional                      Albany    GA   \n",
       "5                 Nantucket Memorial                   Nantucket    MA   \n",
       "6                      Waco Regional                        Waco    TX   \n",
       "7                             Arcata               Arcata/Eureka    CA   \n",
       "8        Atlantic City International               Atlantic City    NJ   \n",
       "9                               Adak                 Adak Island    AK   \n",
       "\n",
       "      Region  \n",
       "0  Northeast  \n",
       "1      South  \n",
       "2       West  \n",
       "3    Midwest  \n",
       "4      South  \n",
       "5  Northeast  \n",
       "6      South  \n",
       "7       West  \n",
       "8  Northeast  \n",
       "9       West  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# good, we're now ready to join this \"Region\" information to our lookup table\n",
    "df_lookup = df_lookup.merge(df_region,on='State',how='left')\n",
    "\n",
    "df_lookup.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add airport latitude and longitude information using Google geocoder\n",
    "\n",
    "- Next we'll query the geograhical latitude/longitude location of each airport using geocoder provided from Google API.\n",
    "\n",
    "- This information will be useful especially when creating visualization plots.\n",
    "\n",
    "- There's a nice Python package for to query lat/lon: https://pypi.python.org/pypi/geocoder\n",
    "\n",
    "- Below will take a while, so a good time to brew more coffee :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(  0 out of 334) Elapsed time:  0.00 seconds\n",
      "( 20 out of 334) Elapsed time: 204.68 seconds\n",
      "( 40 out of 334) Elapsed time: 413.08 seconds\n",
      "( 60 out of 334) Elapsed time: 620.54 seconds\n",
      "( 80 out of 334) Elapsed time: 831.28 seconds\n",
      "(100 out of 334) Elapsed time: 1042.17 seconds\n",
      "(120 out of 334) Elapsed time: 1253.24 seconds\n",
      "(140 out of 334) Elapsed time: 1464.41 seconds\n",
      "(160 out of 334) Elapsed time: 1676.92 seconds\n",
      "(180 out of 334) Elapsed time: 1887.61 seconds\n",
      "(200 out of 334) Elapsed time: 2098.65 seconds\n",
      "(220 out of 334) Elapsed time: 2309.66 seconds\n",
      "(240 out of 334) Elapsed time: 2520.07 seconds\n",
      "(260 out of 334) Elapsed time: 2730.17 seconds\n",
      "(280 out of 334) Elapsed time: 2941.02 seconds\n",
      "(300 out of 334) Elapsed time: 3152.57 seconds\n",
      "(320 out of 334) Elapsed time: 3363.34 seconds\n",
      "-- 22 NANs out 334 (6.59%) --\n"
     ]
    }
   ],
   "source": [
    "import geocoder\n",
    "from util import print_time\n",
    "\n",
    "t = time.time()\n",
    "lat,lon = [],[]\n",
    "\n",
    "n_items = df_lookup.shape[0]\n",
    "for i,airport in enumerate(df_lookup['Airport']):\n",
    "    if i%20==0:\n",
    "         print '({:3} out of {})'.format(i,n_items),print_time(t)\n",
    "    loc = geocoder.google(airport)\n",
    "    time.sleep(10) # add a pause to avoid getting service timed-out\n",
    "\n",
    "    if loc is not None:\n",
    "        lon.append(loc.lng)\n",
    "        lat.append(loc.lat)\n",
    "    else:\n",
    "        # lookup failed\n",
    "        lon.append(None)\n",
    "        lat.append(None)\n",
    "\n",
    "# add as new columns\n",
    "df_lookup['lat'] = lat\n",
    "df_lookup['lon'] = lon\n",
    "\n",
    "n_nans = df_lookup['lat'].isnull().sum(axis=0)\n",
    "print \"-- {} NANs out {} ({:.2f}%) --\".format(n_nans,n_items,n_nans/float(n_items)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 6.59% of the queries failed...\n",
    "\n",
    "- For airports, search using City + State information (lose locality a bit but will suffice for our analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 -- 1 NANs out 334 (0.30%) --\n"
     ]
    }
   ],
   "source": [
    "idx_nan = [] # keep track of the index location that may fail yet again\n",
    "for i in xrange(n_items):\n",
    "    print i,\n",
    "    if lat[i] is not None:\n",
    "        continue\n",
    "    city,state = df_lookup['City'].ix[i], df_lookup['State'].ix[i]\n",
    "    loc = geocoder.google('{}, {}'.format(city,state))\n",
    "    time.sleep(10) # add a pause to avoid getting service timed-out\n",
    "\n",
    "    if loc is not None:\n",
    "        lon[i] = loc.lng\n",
    "        lat[i] = loc.lat\n",
    "    else:\n",
    "        print '    lookup failed for: {}, {}'.format(city,state)\n",
    "        idx_nan.append(i)\n",
    "        \n",
    "# update columns\n",
    "df_lookup['lat'] = lat\n",
    "df_lookup['lon'] = lon\n",
    "\n",
    "n_nans = df_lookup['lat'].isnull().sum(axis=0)\n",
    "print \"-- {} NANs out {} ({:.2f}%) --\".format(n_nans,n_items,n_nans/float(n_items)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So at this point, we have a single lookup failure\n",
    "\n",
    "- Although unelegant, I'll just manually query these in the geocoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Description</th>\n",
       "      <th>Airport</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Region</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>14109</td>\n",
       "      <td>Hattiesburg/Laurel, MS: Hattiesburg-Laurel Reg...</td>\n",
       "      <td>Hattiesburg-Laurel Regional</td>\n",
       "      <td>Hattiesburg/Laurel</td>\n",
       "      <td>MS</td>\n",
       "      <td>South</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Code                                        Description  \\\n",
       "252  14109  Hattiesburg/Laurel, MS: Hattiesburg-Laurel Reg...   \n",
       "\n",
       "                         Airport                City State Region  lat  lon  \n",
       "252  Hattiesburg-Laurel Regional  Hattiesburg/Laurel    MS  South  NaN  NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lookup[df_lookup['lat'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<[OK] Google - Geocode [Hattiesburg, MS, USA]>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one lookup failed...let's just use the cityname before the \"/\" char\n",
    "loc = geocoder.google('Hattiesburg MS')\n",
    "loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Code           0\n",
       "Description    0\n",
       "Airport        0\n",
       "City           0\n",
       "State          0\n",
       "Region         8\n",
       "lat            0\n",
       "lon            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lookup.ix[252,'lat'] = loc.lat\n",
    "df_lookup.ix[252,'lon'] = loc.lng\n",
    "\n",
    "df_lookup.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add column with both city and state\n",
    "\n",
    "- Since I am not familiar with many names of the airport, I'd rather work with City and State names.\n",
    "\n",
    "- However, there may be multiple airports in the same city (eg, JKF and Laguardia in NYC), so uniqueness of \"City/State\" is not guaranteed.\n",
    "\n",
    "- Here, I'll create yet another (and final) column containing both the City and State information, and modify duplicates as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Description</th>\n",
       "      <th>Airport</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Region</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>City_State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>10620</td>\n",
       "      <td>Billings, MT: Billings Logan International</td>\n",
       "      <td>Billings Logan International</td>\n",
       "      <td>Billings</td>\n",
       "      <td>MT</td>\n",
       "      <td>West</td>\n",
       "      <td>45.803738</td>\n",
       "      <td>-108.537214</td>\n",
       "      <td>Billings (MT)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>12888</td>\n",
       "      <td>Laramie, WY: Laramie Regional</td>\n",
       "      <td>Laramie Regional</td>\n",
       "      <td>Laramie</td>\n",
       "      <td>WY</td>\n",
       "      <td>West</td>\n",
       "      <td>41.320194</td>\n",
       "      <td>-105.670345</td>\n",
       "      <td>Laramie (WY)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>12250</td>\n",
       "      <td>Hyannis, MA: Barnstable Municipal-Boardman/Pol...</td>\n",
       "      <td>Barnstable Municipal-Boardman/Polando Field</td>\n",
       "      <td>Hyannis</td>\n",
       "      <td>MA</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>41.667338</td>\n",
       "      <td>-70.284745</td>\n",
       "      <td>Hyannis (MA)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>14222</td>\n",
       "      <td>Pago Pago, TT: Pago Pago International</td>\n",
       "      <td>Pago Pago International</td>\n",
       "      <td>Pago Pago</td>\n",
       "      <td>TT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-14.331389</td>\n",
       "      <td>-170.711389</td>\n",
       "      <td>Pago Pago (TT)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>11525</td>\n",
       "      <td>Elko, NV: Elko Regional</td>\n",
       "      <td>Elko Regional</td>\n",
       "      <td>Elko</td>\n",
       "      <td>NV</td>\n",
       "      <td>West</td>\n",
       "      <td>40.827819</td>\n",
       "      <td>-115.786212</td>\n",
       "      <td>Elko (NV)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Code                                        Description  \\\n",
       "34   10620         Billings, MT: Billings Logan International   \n",
       "180  12888                      Laramie, WY: Laramie Regional   \n",
       "153  12250  Hyannis, MA: Barnstable Municipal-Boardman/Pol...   \n",
       "257  14222             Pago Pago, TT: Pago Pago International   \n",
       "103  11525                            Elko, NV: Elko Regional   \n",
       "\n",
       "                                         Airport       City State     Region  \\\n",
       "34                  Billings Logan International   Billings    MT       West   \n",
       "180                             Laramie Regional    Laramie    WY       West   \n",
       "153  Barnstable Municipal-Boardman/Polando Field    Hyannis    MA  Northeast   \n",
       "257                      Pago Pago International  Pago Pago    TT        NaN   \n",
       "103                                Elko Regional       Elko    NV       West   \n",
       "\n",
       "           lat         lon      City_State  \n",
       "34   45.803738 -108.537214   Billings (MT)  \n",
       "180  41.320194 -105.670345    Laramie (WY)  \n",
       "153  41.667338  -70.284745    Hyannis (MA)  \n",
       "257 -14.331389 -170.711389  Pago Pago (TT)  \n",
       "103  40.827819 -115.786212       Elko (NV)  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lookup['City_State'] = df_lookup['City'] + ' (' + df_lookup['State'] + ')'\n",
    "\n",
    "df_lookup.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Houston (TX)       3\n",
       "Chicago (IL)       2\n",
       "Washington (DC)    2\n",
       "New York (NY)      2\n",
       "Name: City_State, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check duplicates in \"City_State\"\n",
    "dups = df_lookup['City_State'].value_counts()\n",
    "dups = dups[dups != 1]\n",
    "\n",
    "dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{10245: 'King Salmon Airport',\n",
      " 10754: 'Wiley Post/Will Rogers Memorial',\n",
      " 11267: 'James M Cox/Dayton International',\n",
      " 13830: 'Kahului Airport',\n",
      " 14696: 'South Bend International'}\n"
     ]
    }
   ],
   "source": [
    "# create hash-table for airport name lookup\n",
    "hash_airport = df_lookup.set_index('Code')['Airport'].to_dict()\n",
    "pprint({k: hash_airport[k] for k in hash_airport.keys()[:5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Houston (TX)\n",
      "    (Code =      1) Airport = Ellington\n",
      "    (Code = 171407) Airport = William P Hobby\n",
      "    (Code = 478137) Airport = George Bush Intercontinental/Houston\n",
      "Chicago (IL)\n",
      "    (Code = 264913) Airport = Chicago Midway International\n",
      "    (Code = 853523) Airport = Chicago O'Hare International\n",
      "Washington (DC)\n",
      "    (Code = 230760) Airport = Ronald Reagan Washington National\n",
      "    (Code = 135697) Airport = Washington Dulles International\n",
      "New York (NY)\n",
      "    (Code = 302634) Airport = John F. Kennedy International\n",
      "    (Code = 314816) Airport = LaGuardia\n"
     ]
    }
   ],
   "source": [
    "# check duplicates in \"City_State\"\n",
    "for dup in dups.index:\n",
    "    print dup\n",
    "    for i in df_lookup[df_lookup['City_State'] == dup].Code:\n",
    "        print \"    (Code = {:6}) Airport = {}\".format((df_data['ORIGIN_AIRPORT_ID'] == i).sum(), hash_airport[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, kinda hacky, but will create manual replacement on these duplicates using the \"cleaner\" below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "cleaner = [\n",
    "    ('Houston (TX) [Ell]', 'Ellington'), \n",
    "    ('Houston (TX) [WP.Hobby]', 'William P Hobby'), \n",
    "    ('Houston (TX) [G.Bush]',  'George Bush Intercontinental/Houston'), \n",
    "    ('Chicago (IL) [Midway]',   'Chicago Midway International'),\n",
    "    (\"Chicago (IL) [O'Hare]\",   \"Chicago O'Hare International\"),\n",
    "    ('Washington (DC) [R.Reagan]',   'Ronald Reagan Washington National'),\n",
    "    ('Washington (DC) [W.Dulles]',   'Washington Dulles International'),\n",
    "    (\"New York (NY) [JFK]\",   \"John F. Kennedy International\"),\n",
    "    (\"New York (NY) [Lag]\",   \"LaGuardia\"),\n",
    "]\n",
    "\n",
    "for _replace, _airport in cleaner:\n",
    "    df_lookup.loc[df_lookup['Airport'] == _airport, 'City_State'] = _replace\n",
    "\n",
    "# check duplicates are removed\n",
    "assert np.all(df_lookup['City_State'].value_counts() == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All done. Save dataframe on disk\n",
    "\n",
    "- We have created our *enhanced* lookup table.\n",
    "\n",
    "- Let's save this on disk for later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(334, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Description</th>\n",
       "      <th>Airport</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Region</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>City_State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>10739</td>\n",
       "      <td>Brainerd, MN: Brainerd Lakes Regional</td>\n",
       "      <td>Brainerd Lakes Regional</td>\n",
       "      <td>Brainerd</td>\n",
       "      <td>MN</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>46.393046</td>\n",
       "      <td>-94.141263</td>\n",
       "      <td>Brainerd (MN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>11111</td>\n",
       "      <td>Columbia, MO: Columbia Regional</td>\n",
       "      <td>Columbia Regional</td>\n",
       "      <td>Columbia</td>\n",
       "      <td>MO</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>38.817316</td>\n",
       "      <td>-92.221582</td>\n",
       "      <td>Columbia (MO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>11274</td>\n",
       "      <td>Dubuque, IA: Dubuque Regional</td>\n",
       "      <td>Dubuque Regional</td>\n",
       "      <td>Dubuque</td>\n",
       "      <td>IA</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>42.397092</td>\n",
       "      <td>-90.705606</td>\n",
       "      <td>Dubuque (IA)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>11292</td>\n",
       "      <td>Denver, CO: Denver International</td>\n",
       "      <td>Denver International</td>\n",
       "      <td>Denver</td>\n",
       "      <td>CO</td>\n",
       "      <td>West</td>\n",
       "      <td>39.856096</td>\n",
       "      <td>-104.673738</td>\n",
       "      <td>Denver (CO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>11308</td>\n",
       "      <td>Dothan, AL: Dothan Regional</td>\n",
       "      <td>Dothan Regional</td>\n",
       "      <td>Dothan</td>\n",
       "      <td>AL</td>\n",
       "      <td>South</td>\n",
       "      <td>31.321656</td>\n",
       "      <td>-85.452433</td>\n",
       "      <td>Dothan (AL)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>11697</td>\n",
       "      <td>Fort Lauderdale, FL: Fort Lauderdale-Hollywood...</td>\n",
       "      <td>Fort Lauderdale-Hollywood International</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>FL</td>\n",
       "      <td>South</td>\n",
       "      <td>26.074234</td>\n",
       "      <td>-80.150602</td>\n",
       "      <td>Fort Lauderdale (FL)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>12255</td>\n",
       "      <td>Hays, KS: Hays Regional</td>\n",
       "      <td>Hays Regional</td>\n",
       "      <td>Hays</td>\n",
       "      <td>KS</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>38.842222</td>\n",
       "      <td>-99.273167</td>\n",
       "      <td>Hays (KS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>12397</td>\n",
       "      <td>Ithaca/Cortland, NY: Ithaca Tompkins Regional</td>\n",
       "      <td>Ithaca Tompkins Regional</td>\n",
       "      <td>Ithaca/Cortland</td>\n",
       "      <td>NY</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>42.490638</td>\n",
       "      <td>-76.459941</td>\n",
       "      <td>Ithaca/Cortland (NY)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>15356</td>\n",
       "      <td>Trenton, NJ: Trenton Mercer</td>\n",
       "      <td>Trenton Mercer</td>\n",
       "      <td>Trenton</td>\n",
       "      <td>NJ</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>40.277031</td>\n",
       "      <td>-74.818049</td>\n",
       "      <td>Trenton (NJ)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>15412</td>\n",
       "      <td>Knoxville, TN: McGhee Tyson</td>\n",
       "      <td>McGhee Tyson</td>\n",
       "      <td>Knoxville</td>\n",
       "      <td>TN</td>\n",
       "      <td>South</td>\n",
       "      <td>35.810833</td>\n",
       "      <td>-83.993889</td>\n",
       "      <td>Knoxville (TN)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Code                                        Description  \\\n",
       "46   10739              Brainerd, MN: Brainerd Lakes Regional   \n",
       "77   11111                    Columbia, MO: Columbia Regional   \n",
       "87   11274                      Dubuque, IA: Dubuque Regional   \n",
       "89   11292                   Denver, CO: Denver International   \n",
       "91   11308                        Dothan, AL: Dothan Regional   \n",
       "119  11697  Fort Lauderdale, FL: Fort Lauderdale-Hollywood...   \n",
       "154  12255                            Hays, KS: Hays Regional   \n",
       "167  12397      Ithaca/Cortland, NY: Ithaca Tompkins Regional   \n",
       "317  15356                        Trenton, NJ: Trenton Mercer   \n",
       "324  15412                        Knoxville, TN: McGhee Tyson   \n",
       "\n",
       "                                     Airport             City State  \\\n",
       "46                   Brainerd Lakes Regional         Brainerd    MN   \n",
       "77                         Columbia Regional         Columbia    MO   \n",
       "87                          Dubuque Regional          Dubuque    IA   \n",
       "89                      Denver International           Denver    CO   \n",
       "91                           Dothan Regional           Dothan    AL   \n",
       "119  Fort Lauderdale-Hollywood International  Fort Lauderdale    FL   \n",
       "154                            Hays Regional             Hays    KS   \n",
       "167                 Ithaca Tompkins Regional  Ithaca/Cortland    NY   \n",
       "317                           Trenton Mercer          Trenton    NJ   \n",
       "324                             McGhee Tyson        Knoxville    TN   \n",
       "\n",
       "        Region        lat         lon            City_State  \n",
       "46     Midwest  46.393046  -94.141263         Brainerd (MN)  \n",
       "77     Midwest  38.817316  -92.221582         Columbia (MO)  \n",
       "87     Midwest  42.397092  -90.705606          Dubuque (IA)  \n",
       "89        West  39.856096 -104.673738           Denver (CO)  \n",
       "91       South  31.321656  -85.452433           Dothan (AL)  \n",
       "119      South  26.074234  -80.150602  Fort Lauderdale (FL)  \n",
       "154    Midwest  38.842222  -99.273167             Hays (KS)  \n",
       "167  Northeast  42.490638  -76.459941  Ithaca/Cortland (NY)  \n",
       "317  Northeast  40.277031  -74.818049          Trenton (NJ)  \n",
       "324      South  35.810833  -83.993889        Knoxville (TN)  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print df_lookup.shape\n",
    "df_lookup.sample(10).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df_lookup.to_csv('df_lookup.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "toc_position": {
   "height": "615px",
   "left": "0px",
   "right": "1228px",
   "top": "106px",
   "width": "212px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
